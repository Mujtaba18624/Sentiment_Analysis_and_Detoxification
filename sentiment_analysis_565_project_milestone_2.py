# -*- coding: utf-8 -*-
"""Sentiment_Analysis_565_Project_Milestone_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fToXstlAVpxK4wE1MNf2N-pabh_Z7Kj2

# Sentiment Analysis Colx 565
# Sentiment Classification and Text Detoxification Project

**Team Members:**

1. Muhammad Mujtaba Khan
2. Kartik Sirwani

**Citations:**

1. https://github.ubc.ca/MDS-CL-2024-25/COLX_565_sentiment_students/blob/master/tutorials/LLM-Prompting.ipynb
2. https://github.ubc.ca/MDS-CL-2024-25/COLX_565_sentiment_students/blob/master/tutorials/LangChainTutorial-Part-4-LoadingToolsChains.ipynb
3. https://www.marktechpost.com/2025/03/06/a-coding-guide-to-sentiment-analysis-of-customer-reviews-using-ibms-open-source-ai-model-granite-3b-and-hugging-face-transformers/
4. https://huggingface.co/mradermacher/DetoxLLM-7B-i1-GGUF
5. https://huggingface.co/UBC-NLP/toucan-base
6. https://github.ubc.ca/MDS-CL-2024-25/COLX_565_sentiment_students/blob/master/tutorials/LoadQuantizedDetoxLLM.ipynb
7. https://github.ubc.ca/MDS-CL-2024-25/COLX_565_sentiment_students/blob/master/tutorials/LangChainTutorial-Part-5-agents.ipynb

# Loading Libraries and Integrating Drive

## Libraries Installation
"""

!pip install langchain_ollama langchain_community langchain
!pip install transformers langchain_openai langchain_huggingface
!pip install langid
!pip install llama-cpp-python
!pip install langgraph

"""## Integrate Drive folder"""

from google.colab import drive
import os

drive.mount('/content/drive')
# folder_path = '/content/drive/My Drive/UBC_MDS/Colx_565_Sentiment'
folder_path = '/content/drive/My Drive/565_milestone_2'
files = os.listdir(folder_path)
print(files)

"""## Load Libraries"""

import pandas as pd
import os
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer, MT5ForConditionalGeneration
import json
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import langid
from transformers import pipeline
from langchain.llms import HuggingFacePipeline
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.schema.runnable import RunnableLambda
from typing import Literal, TypedDict
from langgraph.graph import StateGraph, END
from langgraph.types import Command, Send
from langchain_core.messages import HumanMessage
from langchain_community.llms import LlamaCpp
from llama_cpp import Llama
from IPython.display import display, Image
import re
from sklearn.metrics import cohen_kappa_score

"""# Langraph Pipeline

## Models

### Language Detection Function
"""

def classify_language(sentence):
    lang, _ = langid.classify(sentence)
    if lang == 'en':
        return 'English'
    else:
        return 'African'

"""### Translation Model"""

tokenizer_translate = AutoTokenizer.from_pretrained("UBC-NLP/toucan-base")
translate_model = MT5ForConditionalGeneration.from_pretrained("UBC-NLP/toucan-base", torch_dtype=torch.float16, device_map="auto")
translate_model.eval()

translate_pipeline = pipeline(
    task="text2text-generation",
    model=translate_model,
    tokenizer=tokenizer_translate,
    torch_dtype=torch.float16,
    max_new_tokens=50,
    temperature=0.6,
    do_sample=True,
    top_p = 0.9,
    num_beams=5
)

translate_llm = HuggingFacePipeline(pipeline=translate_pipeline)

def translate_language(input_text):

    return translate_llm.invoke("eng: "+ input_text)

"""### Sentiment Model"""

tokenizer_sentiment = AutoTokenizer.from_pretrained("ibm-granite/granite-3.0-2b-instruct")
sentiment_model = AutoModelForCausalLM.from_pretrained("ibm-granite/granite-3.0-2b-instruct", device_map="auto", torch_dtype=torch.float16)
sentiment_model.eval()

sentiment_pipeline = pipeline(
    task="text-generation",
    model=sentiment_model,
    tokenizer=tokenizer_sentiment,
    torch_dtype=torch.float16,
    max_new_tokens=250,
    temperature=0.6,
    top_p=0.9,
    do_sample=True,
    return_full_text=False
)

sentiment_llm = HuggingFacePipeline(pipeline=sentiment_pipeline)


def extract_sentiment_and_explanation(output):
    sentiment_match = re.search(r'"sentiment":\s*"([^"]+)"', output)
    explanation_match = re.search(r'"explanation":\s*"([^"]+)"', output)

    sentiment = sentiment_match.group(1).lower() if sentiment_match else None
    explanation = explanation_match.group(1) if explanation_match else "Failed to extract sentiment."

    return sentiment, explanation

def get_sentiment(input_text):
    sentiment_prompt = PromptTemplate(
        input_variables=["text"],
        template=(
            "You are an expert sentiment analysis assistant. "
            "Classify the given text as 'positive', 'negative', or 'mixed'. "
            "Provide your response in the following JSON format:\n\n"
            "{{\n"
            '  "sentiment": "<positive/negative/mixed>",\n'
            '  "explanation": "<Brief explanation of sentiment>"\n'
            "}}\n\n"
            "Analyze the sentiment of the following sentence: {text}"
        )
    )
    sentiment_chain = sentiment_prompt | sentiment_llm | RunnableLambda(lambda x: x.strip())
    output = sentiment_chain.invoke({"text": input_text})

    return extract_sentiment_and_explanation(output)

"""### Toxicity Detection and Detoxification Model"""

device = "cuda"
model_path = "UBC-NLP/DetoxLLM-7B"
tokenizer = AutoTokenizer.from_pretrained(model_path)
toxicity_model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto", torch_dtype=torch.float16)
toxicity_model.eval()


toxicity_pipeline = pipeline(
    task="text-generation",
    model=toxicity_model,
    tokenizer=tokenizer,
    torch_dtype=torch.float16,
    max_new_tokens=50,
    temperature=0.75,
    do_sample=True,
    return_full_text=False
)

toxicity_llm = HuggingFacePipeline(pipeline=toxicity_pipeline)

def parse_toxicity_output(output_text):
    result = {"toxicity_label": None, "explanation": None}
    lines = output_text.strip().split("\n")

    for line in lines:
        if "Toxicity Label" in line:
            label = line.split(":")[1].strip().lower()
            result["toxicity_label"] = label
        elif "Explanation:" in line:
            explanation = line.split("Explanation:", 1)[-1].strip()
            result["explanation"] = explanation

    return result


def get_toxicity(input_text):
    toxicity_prompt = PromptTemplate(
    input_variables=["text"],  # Ensure it takes input from LangChain
    template=(
        "You are an expert Toxicity Classifier. Classify the text as toxic or not-toxic and also provide explanation.\n"
        "Here are a few examples of your task:\n\n"

        "Sentence: \"You are completely clueless.\"\n"
        "Toxicity Label: toxic\n"
        "Explanation: Insulting language directed at the recipient.\n\n"

        "Sentence: \"go blow your bitch GabrielF =\"\n"
        "Toxicity Label: toxic\n"
        "Explanation: Offensive language like bitch used\n\n"

        "Sentence: \"Kill yourself! Fuckin' bastard!\"\n"
        "Toxicity Label: toxic\n"
        "Explanation: Offensive language and personal attack aimed at recipient's life.\n\n"

        "Sentence: \"No, you're being unwise.\"\n"
        "Toxicity Label: non-toxic\n"
        "Explanation: This input text is not toxic.\n\n"

        "Sentence: \"{text}\""
      )
    )
    toxicity_chain = toxicity_prompt | toxicity_llm | RunnableLambda(lambda x: parse_toxicity_output(x))
    output = toxicity_chain.invoke({"text": input_text})
    print(output)
    return output["toxicity_label"], output["explanation"]

def detoxify_text(input_text):
    detoxify_prompt = PromptTemplate(
        input_variables=["text"],
        template="Detoxify the following toxic sentence:\n{text}\nNon-toxic version:"
    )
    detoxify_chain = detoxify_prompt | toxicity_llm | RunnableLambda(lambda x: x.strip())
    return detoxify_chain.invoke({"text": input_text})

"""## LangGraph Workflow Pipeline

### Defining Nodes and State
"""

class State(TypedDict):
    input_text: str
    translated_text: str
    sentiment_label: str
    sentiment_explanation: str
    toxicity_label: str
    toxicity_explanation: str
    detoxified_text: str

# Defining Nodes

def language_detection_node(state: State) -> Command[Literal["translate", "sentiment"]]:
    language = classify_language(state["input_text"])
    if language == "English":

        return Command(
            goto="sentiment",
            update={"translated_text": state["input_text"]}  # Set translated_text to the input text
        )
    else:
        # If the text is not in English, go to the translation node
        return Command(
              goto="translate",
              update={"translated_text": state["input_text"]}
            )

def translate_node(state: State) -> Command[Literal["sentiment"]]:
    translated_text = translate_language(state["input_text"])
    return Command(
        goto="sentiment",
        update={"translated_text": translated_text}  # Update translated_text in the state
    )

def sentiment_node(state: State) -> Command[Literal["toxicity"]]:
    sentiment_label, sentiment_explanation = get_sentiment(state["translated_text"])
    return Command(
        goto="toxicity",
        update={
            "sentiment_label": sentiment_label,
            "sentiment_explanation": sentiment_explanation
        }
    )

def toxicity_node(state: State) -> Command[Literal["detoxify", "__end__"]]:
    toxicity_label, toxicity_explanation = get_toxicity(state["translated_text"])
    if toxicity_label == "toxic":
        return Command(
            goto="detoxify",
            update={
                "toxicity_label": toxicity_label,
                "toxicity_explanation": toxicity_explanation
                }
            )
    else:
        return Command(
            goto=END,
            update={
                "toxicity_label": toxicity_label,
                "toxicity_explanation": toxicity_explanation,
                "detoxified_text": None
            }
        )

def detoxify_node(state: State) -> Command[Literal["__end__"]]:
    detoxified_text = detoxify_text(state["translated_text"])
    return Command(
        goto=END,
        update={"detoxified_text": detoxified_text}
    )

"""### Building Edges of the Graph"""

# Build the graph
builder = StateGraph(State)
builder.add_node("language_detection", language_detection_node)
builder.add_node("translate", translate_node)
builder.add_node("sentiment", sentiment_node)
builder.add_node("toxicity", toxicity_node)
builder.add_node("detoxify", detoxify_node)

builder.set_entry_point("language_detection")
builder.add_edge("language_detection", "sentiment")
builder.add_edge("translate", "sentiment")
builder.add_edge("sentiment", "toxicity")
builder.add_edge("toxicity", END)
builder.add_edge("detoxify", END)

graph = builder.compile()

"""### Defining the Run Workflow

"""

display(Image(graph.get_graph().draw_mermaid_png()))

def run_workflow(input_text):
    initial_state = {"input_text": input_text}
    final_state = graph.invoke(initial_state)
    return {
        "sentiment_label": final_state["sentiment_label"],
        "sentiment_explanation": final_state["sentiment_explanation"],
        "toxicity_label": final_state["toxicity_label"],
        "toxicity_explanation": final_state["toxicity_explanation"],
        "detoxified_text": final_state["detoxified_text"]
    }

"""### Examples"""

# Example Usage 1
input_text = "This is very bad and terrible product unfortunately I will never step my foot in this place again"
result = run_workflow(input_text)
print("Output: \n", result)

# Example Usage 2
input_text = "Loved this restaurant, delicious menu and amazing service by the staff"
result = run_workflow(input_text)
print("Output: \n", result)

# Example Usage 3
input_text = "Nashukuru huduma ya haraka, lakini chakula kimefika kikiwa baridi, si tamu kamwe."
result = run_workflow(input_text)
print("Output: \n", result)

"""# Inferencing Pipeline

## Loading Datasets
"""

sentiment_csv_path = os.path.join(folder_path, "Milstone-2-multilingual-sentiment-test-solutions.csv")
sentiment_df = pd.read_csv(sentiment_csv_path)

sentiment_df

toxic_csv_path = os.path.join(folder_path, "Milestone-2-toxic-test-solutions.csv")


toxic_df = pd.read_csv(toxic_csv_path)

toxic_df

"""## Running Inferences"""

def run_workflow_on_dataframe(df, sentence_column, output_csv_path, batch_size=10):
    """
    Perform inference on a DataFrame and save results to a CSV file.

    Args:
        df (pd.DataFrame): Input DataFrame containing the sentences.
        sentence_column (str): Name of the column containing the sentences.
        output_csv_path (str): Path to the output CSV file.
        batch_size (int): Number of rows to process before saving progress.
    """
    # Define the new columns to be added
    new_columns = [
        "pred_sentiment_label",
        "sentiment_explanation",
        "pred_toxicity_label",
        "toxicity_explanation",
        "detoxified_text"
    ]

    if os.path.exists(output_csv_path):
        result_df = pd.read_csv(output_csv_path)

        # Find the first row where ALL new columns are NaN (fully unprocessed)
        unprocessed_rows = result_df[new_columns].isna().all(axis=1)

        if unprocessed_rows.any():
            start_index = unprocessed_rows.idxmax()  # First completely empty row
        else:
            start_index = len(result_df)  # Everything is already processed

        print(f"Resuming from index: {start_index}")

    else:
        result_df = df.copy()
        for col in new_columns:
            result_df[col] = None  # Initialize columns
        start_index = 0
        print("Starting fresh from index: 0")

    # Iterate over the DataFrame starting from the last processed row
    for i in range(start_index, len(df)):
        sentence = df.loc[i, sentence_column]

        # Perform inference using the LangGraph workflow
        try:
            result = run_workflow(sentence)
            result_df.at[i, "pred_sentiment_label"] = result["sentiment_label"]
            result_df.at[i, "sentiment_explanation"] = result["sentiment_explanation"]
            result_df.at[i, "pred_toxicity_label"] = result["toxicity_label"]
            result_df.at[i, "toxicity_explanation"] = result["toxicity_explanation"]
            result_df.at[i, "detoxified_text"] = result["detoxified_text"]
        except Exception as e:
            print(f"Error processing row {i}: {e}")
            continue
        # result = run_workflow(sentence)



        # Save progress after every batch_size rows
        if (i + 1) % batch_size == 0:
            result_df.to_csv(output_csv_path, index=False)
            print(f"Processed {i + 1} rows. Progress saved to {output_csv_path}")


    # Save the final results
    result_df.to_csv(output_csv_path, index=False)
    print(f"Inference completed. Results saved to {output_csv_path}")
    return result_df

"""### Inference on Sentiment Data"""

output_csv_path = os.path.join(folder_path, "Inferenced-Milstone-2-multilingual-sentiment-test-solutions.csv")   # Path to the output CSV file
sentence_column = "sentence"

# Run the workflow on the DataFrame
infer_sentiment_df = run_workflow_on_dataframe(sentiment_df, sentence_column, output_csv_path, batch_size=10)

"""### Inference on Toxicity Data"""

output_csv_path = os.path.join(folder_path, "Inferenced-Milestone-2-toxic-test-solutions.csv")
sentence_column = "text"

# Run the workflow on the DataFrame
infer_toxic_df = run_workflow_on_dataframe(toxic_df, sentence_column, output_csv_path, batch_size=10)

"""### Loading inferenced data"""

sentiment_infer_path = os.path.join(folder_path, "Inferenced-Milstone-2-multilingual-sentiment-test-solutions.csv")
toxic_infer_path = os.path.join(folder_path, "Inferenced-Milestone-2-toxic-test-solutions.csv")
infer_sentiment_df = pd.read_csv(sentiment_infer_path)
infer_toxic_df = pd.read_csv(toxic_infer_path)

infer_sentiment_df['pred_sentiment_label'].value_counts()

infer_toxic_df['pred_toxicity_label'].value_counts()

"""We observe that the predicted toxic labels are not clean for non-toxic, so we will clean it"""

def clean_toxic_label(label):
  if label == 'toxic':
    return 'toxic'
  else:
    return 'non-toxic'

infer_toxic_df['pred_toxicity_label'] = infer_toxic_df['pred_toxicity_label'].apply(lambda x: clean_toxic_label(x))

infer_toxic_df['pred_toxicity_label'].value_counts()

infer_toxic_df.to_csv("Inferenced-Milestone-2-toxic-test-solutions.csv")

"""Preparing detoxified files for Annotators"""

detoxified_df_1 = infer_toxic_df[(infer_toxic_df['pred_toxicity_label']=='toxic') & (infer_toxic_df['source_label']=='toxic')].head(15)
detoxified_df_1 = detoxified_df_1[['data_id', 'text','detoxified_text']]

detoxified_df_2 = detoxified_df_1.copy(deep=True)

detoxified_df_1['Annotator_Muhammad'] = ""
detoxified_df_2['Annotator_Kartik'] = ""

detoxified_df_1.to_csv('Muhammad_detoxified_dataset.csv', index=False)
detoxified_df_2.to_csv('Kartik_detoxified_dataset.csv', index=False)

"""## Metrics Calculation"""

def calculate_metrics(true_labels, predicted_labels):
  accuracy = accuracy_score(true_labels, predicted_labels)
  precision = precision_score(true_labels, predicted_labels, average='weighted')
  recall = recall_score(true_labels, predicted_labels, average='weighted')
  f1 = f1_score(true_labels, predicted_labels, average='weighted')

  print("\nMetrics:")
  print(f"Accuracy: {accuracy}")
  print(f"Precision: {precision}")
  print(f"Recall: {recall}")
  print(f"F1 Score: {f1}")

"""### Sentiment Classification Metrics"""

calculate_metrics(infer_sentiment_df['class-label'], infer_sentiment_df['pred_sentiment_label'])

"""### Toxicity Labelling Metrics"""

calculate_metrics(infer_toxic_df['source_label'], infer_toxic_df['pred_toxicity_label'])

"""## Detoxification evaluation"""

pth_1 = 'Muhammad_detoxified_dataset.csv'
pth_2 = 'Kartik_detoxified_dataset.csv'
detoxified_df_1 = pd.read_csv(pth_1)
detoxified_df_2 = pd.read_csv(pth_2)

"""Joining two annotator scores"""

merged_detox_df = detoxified_df_1.merge(
    detoxified_df_2[['data_id', 'Annotator_Kartik']],
    on="data_id",
    how="left"
)

merged_detox_df["Average_Score"] = (merged_detox_df["Annotator_Muhammad"]+ merged_detox_df["Annotator_Kartik"])/2
merged_detox_df.head(3)

merged_detox_df.to_csv("Annotated_detoxified_scores.csv")

"""Compute Cohen's Kappa"""

kappa = cohen_kappa_score(merged_detox_df["Annotator_Muhammad"], merged_detox_df["Annotator_Kartik"])

print(f"Cohen's Kappa Score: {kappa:.3f}")